{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKw+fS+dyACCkr/uQR9dVZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/basugautam/Reproducibility-Challenge-Project/blob/Architecture-Files/1implenetation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### üì¶ Step 1: Installing Required Libraries\n",
        "\n",
        "#In this step, we install all necessary Python packages to perform deep learning, data handling, and visualization. These include:\n",
        "#- `torch`, `torchvision`: for building and training neural networks.\n",
        "#- `pandas`, `numpy`: for handling and manipulating time series data.\n",
        "#- `scikit-learn`: for data splitting and preprocessing utilities.\n",
        "#- `matplotlib`: for plotting graphs to visualize error and loss.\n",
        "#- `einops`: for tensor manipulation, commonly used in transformer models.\n",
        "\n",
        "#These packages form the basic toolkit for our forecasting project using loss shaping constraints.\n"
      ],
      "metadata": {
        "id": "1A9q9dgh88TO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpGoj4YC7BNu",
        "outputId": "6b0a3c7d-4ba5-493a-d346-4e27435934b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "--2025-04-10 00:05:08--  https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTm1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10360719 (9.9M) [text/plain]\n",
            "Saving to: ‚ÄòETTm1.csv.3‚Äô\n",
            "\n",
            "ETTm1.csv.3         100%[===================>]   9.88M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-04-10 00:05:08 (95.8 MB/s) - ‚ÄòETTm1.csv.3‚Äô saved [10360719/10360719]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# STEP 1: Install Required Libraries\n",
        "!pip install einops\n",
        "!pip install torch torchvision\n",
        "!pip install pandas numpy matplotlib scikit-learn\n",
        "\n",
        "# STEP 2: Download the Dataset\n",
        "!wget https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTm1.csv\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###  Step 2: Downloading the Time Series Dataset\n",
        "\n",
        "#We use the **ETTm1** dataset (15-minute resolution Electricity Transformer Temperature) from the ETT benchmark, which is widely used for long-term time series forecasting.\n",
        "\n",
        "#This dataset is downloaded directly from GitHub, and contains hourly sensor readings for electric transformers. We'll preprocess it in the next step to prepare inputs for our model.\n"
      ],
      "metadata": {
        "id": "P0u6qaIy9Ey7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess(path, input_len=96, pred_len=96):\n",
        "    df = pd.read_csv(path)\n",
        "    df = df.drop(columns=['date'])\n",
        "    data = df.values.astype(np.float32)\n",
        "    mean, std = data.mean(), data.std()\n",
        "    data = (data - mean) / std\n",
        "\n",
        "    X, Y = [], []\n",
        "    for i in range(len(data) - input_len - pred_len):\n",
        "        X.append(data[i:i+input_len])\n",
        "        Y.append(data[i+input_len:i+input_len+pred_len])\n",
        "    return torch.tensor(X), torch.tensor(Y)\n",
        "\n",
        "X, Y = load_and_preprocess(\"ETTm1.csv\")\n",
        "dataset = TensorDataset(X, Y)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXTJQ5J77Hbv",
        "outputId": "8aa447fb-74ef-4253-e2fc-285da72e6051"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-a6e3d43f3db9>:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  return torch.tensor(X), torch.tensor(Y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###  Step 3: Preprocessing and Windowing the Time Series Data\n",
        "\n",
        "#Here, we:\n",
        "#- Remove the date column and normalize the feature values using z-score normalization.\n",
        "#- Create rolling windows to prepare the data for supervised learning:\n",
        " # - `input_len`: Number of historical steps used for prediction.\n",
        " # - `pred_len`: Number of future steps the model should forecast.\n",
        "\n",
        "#Each sample becomes a pair `(input_window, prediction_window)`. These are then converted into PyTorch tensors for use in training and evaluation.\n"
      ],
      "metadata": {
        "id": "pbQh-gwx9L8u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64, pred_len=96):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=4),\n",
        "            num_layers=2\n",
        "        )\n",
        "        self.decoder = nn.Linear(hidden_dim, pred_len)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=1)\n",
        "        return self.decoder(x)\n"
      ],
      "metadata": {
        "id": "f-n5o1ix7RfS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### üîß Step 4: Building a Simple Transformer Model\n",
        "\n",
        "#We define a minimal transformer encoder-based model:\n",
        "#- First, we embed input features into a higher-dimensional space.\n",
        "#- Then, we pass the input through a transformer encoder (multi-head self-attention).\n",
        "#- Finally, the output is averaged across time steps and passed through a linear decoder to predict future values.\n",
        "\n",
        "#This simple model captures sequential dependencies and long-term patterns in time series.\n"
      ],
      "metadata": {
        "id": "q7uFy-iH9QS9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleTransformer(input_dim=X.shape[2])\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "Tp = Y.shape[1]\n",
        "lambda_ = torch.zeros(Tp, requires_grad=False)\n",
        "zeta = torch.zeros(Tp, requires_grad=True)\n",
        "eps = torch.ones(Tp) * 0.5  # baseline constraint\n",
        "h = lambda z: torch.norm(z, p=2)**2\n",
        "\n",
        "for epoch in range(5):\n",
        "    for xb, yb in loader:\n",
        "        preds = model(xb)\n",
        "        per_step_loss = (preds - yb).pow(2).mean(dim=0)\n",
        "\n",
        "        slack = per_step_loss - (eps + zeta)\n",
        "        loss_main = per_step_loss.mean() + h(zeta)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_main.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            zeta -= 0.01 * (2 * zeta - lambda_)\n",
        "            zeta = zeta.clamp(min=0)\n",
        "            lambda_ += 0.01 * slack\n",
        "            lambda_ = lambda_.clamp(min=0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss_main.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "9e2RL9yx7Xd3",
        "outputId": "eeae8e03-38ce-4987-befa-d671180a638c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (96) must match the size of tensor b (7) at non-singleton dimension 2",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d25f25402bc7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mper_step_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mslack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mper_step_loss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mzeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (96) must match the size of tensor b (7) at non-singleton dimension 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###  Step 5: Training with Loss Shaping Constraints (Primal-Dual)\n",
        "\n",
        "# We now implement the **core idea** of the paper:\n",
        "#- Instead of minimizing average loss (ERM), we constrain the per-step losses to stay under `Œµ + Œ∂`.\n",
        "#- We alternate updates for:\n",
        "#  - `Œ∏`: model parameters using gradient descent.\n",
        " # - `Œ∂`: slack variables (relaxation) via gradient descent.\n",
        " # - `Œª`: dual variables (multipliers) via gradient ascent.\n",
        "\n",
        "#This technique reshapes the loss distribution across future time steps, improving consistency in forecasts.\n"
      ],
      "metadata": {
        "id": "vAFvLRUN9VMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(X[:32])\n",
        "    mse = ((preds - Y[:32])**2).mean(dim=0).cpu().numpy()\n",
        "\n",
        "plt.plot(mse)\n",
        "plt.title(\"Per-Step MSE Across Prediction Window\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "u25soNID7Zhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###  Step 6: Visualizing the Per-Step Forecasting Error\n",
        "\n",
        "#We plot the Mean Squared Error (MSE) for each forecast step (1 to `Tp`), showing how the error varies across the prediction horizon.\n",
        "\n",
        "#This helps us observe:\n",
        "- Whether the loss is uniformly distributed (desired).\n",
        "- If there are spikes at certain future steps.\n",
        "#This is critical for evaluating long-term consistency in time series forecasting.\n"
      ],
      "metadata": {
        "id": "kfPMTRB09aeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exponential increase: eps_t = base + growth_rate * exp(step / Tp)\n",
        "import math\n",
        "\n",
        "Tp = Y.shape[1]\n",
        "step_range = torch.arange(Tp)\n",
        "eps = 0.2 + 0.3 * torch.exp(0.01 * step_range)  # exponentially increasing upper bound\n"
      ],
      "metadata": {
        "id": "DFcLN_Ca7cIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### üìà Step 7: Using Exponential Constraints for Forecast Steps\n",
        "\n",
        "#Instead of using a constant error limit across all steps, we apply an **exponentially increasing constraint**:\n",
        "#- Errors closer to the current time are penalized more.\n",
        "#- Farther errors are allowed more flexibility.\n",
        "\n",
        "#This mimics realistic scenarios where distant predictions are inherently more uncertain.\n"
      ],
      "metadata": {
        "id": "8LOaUrqZ9f2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, shuffle=False)\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(X_train, Y_train), batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(TensorDataset(X_val, Y_val), batch_size=32, shuffle=False)\n",
        "\n",
        "train_logs, val_logs = [], []\n"
      ],
      "metadata": {
        "id": "VMHHvKKX7mjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### üß™ Step 8: Splitting Data into Train and Validation Sets\n",
        "\n",
        "#We split the dataset chronologically into:\n",
        "#- Training data: for learning model weights.\n",
        "#- Validation data: for evaluating generalization.\n",
        "\n",
        "#This split is crucial to prevent data leakage in time series tasks and to monitor overfitting.\n"
      ],
      "metadata": {
        "id": "c4sq4vKb9mhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        preds = model(xb)\n",
        "        per_step_loss = (preds - yb).pow(2).mean(dim=0)\n",
        "\n",
        "        slack = per_step_loss - (eps + zeta)\n",
        "        loss_main = per_step_loss.mean() + h(zeta)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_main.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            zeta -= 0.01 * (2 * zeta - lambda_)\n",
        "            zeta = zeta.clamp(min=0)\n",
        "            lambda_ += 0.01 * slack\n",
        "            lambda_ = lambda_.clamp(min=0)\n",
        "\n",
        "        epoch_loss += loss_main.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0\n",
        "        for xb, yb in val_loader:\n",
        "            preds = model(xb)\n",
        "            val_loss += ((preds - yb) ** 2).mean().item()\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "    train_logs.append(epoch_loss / len(train_loader))\n",
        "    val_logs.append(val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Train: {train_logs[-1]:.4f}, Val: {val_logs[-1]:.4f}\")\n"
      ],
      "metadata": {
        "id": "EwG8nWIi7plu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### üîÅ Step 9: Enhanced Training Loop with Train/Validation Logging\n",
        "\n",
        "#We improve the training loop by:\n",
        "#- Logging both training and validation loss after every epoch.\n",
        "#- Ensuring evaluation is done in `eval` mode.\n",
        "#- Storing losses for plotting and TensorBoard logging.\n",
        "\n",
        "#This allows us to monitor learning progression and compare performances across epochs.\n"
      ],
      "metadata": {
        "id": "ffJkkkv-9qMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_logs, label=\"Train Loss\")\n",
        "plt.plot(val_logs, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lCjZ3X9a7tFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### üìâ Step 10: Plotting Train vs Validation Loss\n",
        "\n",
        "#We visualize:\n",
        "#- How the model improves (or deteriorates) over time.\n",
        "#- When the training starts overfitting (if val loss diverges).\n",
        "\n",
        "##This diagnostic plot is essential for early stopping and hyperparameter tuning.\n"
      ],
      "metadata": {
        "id": "EnQPEP969tUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(X_val[:32])\n",
        "    mse = ((preds - Y_val[:32])**2).mean(dim=0).cpu().numpy()\n",
        "\n",
        "plt.plot(eps, label=\"Constraint (œµ)\")\n",
        "plt.plot(mse, label=\"Validation MSE per step\")\n",
        "plt.xlabel(\"Forecast Step\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.title(\"Loss Shaping Effect (with Exponential Constraint)\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1Fj_Dm4P7y3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### üßæ Step 11: Visualizing Constraints vs Actual MSE\n",
        "\n",
        "#Here, we compare:\n",
        "#- The actual forecast errors at each step (validation MSE).\n",
        "#- The constraint `Œµ` applied at each step.\n",
        "\n",
        "#This lets us see how well the model adhered to the desired constraint structure across the prediction horizon.\n"
      ],
      "metadata": {
        "id": "M2cE_E1B9xZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install TensorBoard and set up logging directory\n",
        "%load_ext tensorboard\n",
        "import os\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "log_dir = \"./runs/loss_shaping\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "writer = SummaryWriter(log_dir)\n"
      ],
      "metadata": {
        "id": "wx0DPWwc77Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### üìä Step 12: TensorBoard Logging Setup\n",
        "\n",
        "#We integrate **TensorBoard**, a powerful tool to:\n",
        "- Track training and validation loss.\n",
        "- Monitor how MSE evolves per forecast step.\n",
        "- Visualize dual variable effects and constraint adherence.\n",
        "\n",
        "#TensorBoard enables detailed insights into model behavior.\n"
      ],
      "metadata": {
        "id": "Uw0aIrQo90_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    writer.add_scalar(\"Loss/Train\", train_logs[-1], epoch)\n",
        "    writer.add_scalar(\"Loss/Validation\", val_logs[-1], epoch)\n",
        "\n",
        "    # Log per-step constraint vs val MSE at specific epochs\n",
        "    if epoch % 2 == 0:\n",
        "        with torch.no_grad():\n",
        "            preds = model(X_val[:32])\n",
        "            step_mse = ((preds - Y_val[:32])**2).mean(dim=0)\n",
        "            for i in range(Tp):\n",
        "                writer.add_scalar(f\"MSE_Step/Step_{i}\", step_mse[i], epoch)\n",
        "                writer.add_scalar(f\"Constraint/Step_{i}\", eps[i], epoch)\n"
      ],
      "metadata": {
        "id": "0EMxoyER78xM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### üß† Step 13: Logging Scalars and Per-Step Errors to TensorBoard\n",
        "\n",
        "#We log:\n",
        "- Total training and validation loss each epoch.\n",
        "- Per-step MSE and constraint values at selected intervals.\n",
        "\n",
        "#This provides deep visibility into how each time-step behaves across epochs and helps analyze constraint violations.\n"
      ],
      "metadata": {
        "id": "1TInvULH94zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch TensorBoard\n",
        "%tensorboard --logdir runs/loss_shaping\n"
      ],
      "metadata": {
        "id": "gsslEnqx8BM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### üöÄ Step 14: Launching TensorBoard for Visualization\n",
        "\n",
        "#This launches the live TensorBoard interface in Colab where you can:\n",
        "- Explore time series plots of loss, constraints, and MSE.\n",
        "- Compare training behavior across configurations.\n"
      ],
      "metadata": {
        "id": "SRhHidd-98Ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save after training\n",
        "torch.save(model.state_dict(), \"loss_shaping_model.pt\")\n"
      ],
      "metadata": {
        "id": "RzZFjWnF8Fz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### üíæ Step 15: Saving and Reloading the Model\n",
        "\n",
        "#After training:\n",
        "- Save model weights to a `.pt` file.\n",
        "- Reload later for evaluation, re-training, or deployment.\n",
        "\n",
        "#This ensures reproducibility and prevents losing progress between sessions.\n"
      ],
      "metadata": {
        "id": "Avht1n1m9_In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load before evaluation or continuing training\n",
        "model.load_state_dict(torch.load(\"loss_shaping_model.pt\"))\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "HBaWEEdh8NDQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}