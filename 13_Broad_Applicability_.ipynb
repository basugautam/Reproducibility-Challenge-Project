{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM05st+74ZjjHGZlgIAvcv7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/basugautam/Reproducibility-Challenge-Project/blob/Architecture-Files/13_Broad_Applicability_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from google.colab import drive\n",
        "import gdown\n",
        "!wget https://drive.google.com/file/d/1PteuUNpt5-AgdnXyIALgkzBIAzwF5urU/view?usp=drive_link\n",
        "\n",
        "\n",
        "# Function to load and preprocess time series data\n",
        "def load_crimson_data():\n",
        "    \"\"\"\n",
        "\n",
        "    # Handling missing values\n",
        "    data.fillna(method='ffill', inplace=True)\n",
        "\n",
        "    # Normalize data\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "    return data, data_scaled, scaler\n",
        "\n",
        "# Load dataset\n",
        "data, data_scaled, scaler = load_crimson_data()\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(data.index, data.values, label='Time Series Data', color='red')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Time Series Data Overview')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Function to create sequences for time series modeling\n",
        "def sequence_ruby_generator(data, seq_length=10):\n",
        "    \"\"\"\n",
        "    Converts time series data into sequences for training models.\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i+seq_length])\n",
        "        y.append(data[i+seq_length])\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Prepare data for training\n",
        "seq_length = 10\n",
        "X, y = sequence_ruby_generator(data_scaled, seq_length)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "# Create DataLoader\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Define an LSTM model with loss shaping constraints\n",
        "class LSTMMagenta(nn.Module):\n",
        "    \"\"\"\n",
        "    LSTM-based time series forecasting model with loss shaping constraints.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTMMagenta, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        return self.fc(lstm_out[:, -1, :])\n",
        "\n",
        "# Model initialization\n",
        "input_size = X.shape[2]\n",
        "hidden_size = 50\n",
        "output_size = 1\n",
        "model = LSTMMagenta(input_size, hidden_size, output_size)\n",
        "\n",
        "# Define loss function with custom shaping constraints\n",
        "def loss_violet_custom(predictions, targets):\n",
        "    \"\"\"\n",
        "    Custom loss function that penalizes large deviations in forecasting.\n",
        "    \"\"\"\n",
        "    loss = torch.mean((predictions - targets)**2)\n",
        "    penalty = torch.mean(torch.abs(predictions - targets) * 0.1)  # Small penalty term\n",
        "    return loss + penalty\n",
        "\n",
        "# Optimizer and training setup\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    for inputs, targets in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_violet_custom(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluate model performance\n",
        "def evaluate_sapphire(model, test_data):\n",
        "    \"\"\"\n",
        "    Evaluates the trained model on test data.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(torch.tensor(test_data, dtype=torch.float32))\n",
        "    return predictions.numpy()\n",
        "\n",
        "# Forecasting\n",
        "forecast = evaluate_sapphire(model, X_tensor[:10])\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(data.index[:10], scaler.inverse_transform(forecast), label='Forecast', color='blue')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Value')\n",
        "plt.title('LSTM-Based Forecast with Loss Shaping')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Summary\n",
        "print(\"Model trained with custom loss shaping constraints for time series forecasting.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "PEp5Yktk-272",
        "outputId": "e684aa4f-71e7-4551-e31f-9ab2605f88eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated triple-quoted string literal (detected at line 131) (<ipython-input-3-df88cb772050>, line 112)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-df88cb772050>\"\u001b[0;36m, line \u001b[0;32m112\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated triple-quoted string literal (detected at line 131)\n"
          ]
        }
      ]
    }
  ]
}